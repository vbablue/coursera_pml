Load libraries

```{r}
library(caret)
library(ggplot2)
library(dplyr)
library(parallel)
library(doParallel)

```


Reading the training data
```{r}
df <- read.csv("pml-training.csv", na.strings=c("NA", "#DIV/0!", ""))
df <- df[,colSums(is.na(df)) == 0]
df <- df[,-1]
df <- select(df, -(raw_timestamp_part_1:cvtd_timestamp))
cols <- colnames(df)

```



#Creating partitions for testing and training
```{r}
inTrain <- createDataPartition(y=df$classe,p=0.60, list=FALSE)
training <- df[inTrain,]
testing <- df[-inTrain,]

```


#Train the model with Random forests
```{r}
registerDoParallel(clust <- makeCluster(detectCores()))
model <- train(training$classe ~ ., data=training, method="rf",trControl=trainControl(method = "cv", number = 10))
stopCluster(clust)

```


#Explore the results
```{r}
model$results
model$bestTune
model$finalModel
```


#Cross Validation
```{r}
confusionMatrix(predict(model, newdata=testing), testing$classe)
plot(varImp(model))
```


#Predict and explore
```{r}
prediction <- predict(model, testing) 
new_testing <- cbind(testing,prediction)
select(new_testing, user_name, classe, prediction)
table(prediction,testing$classe)

```


#Final Prediction
#Reading the validation set or the Final submission set.
```{r}
validation <- read.csv("pml-testing.csv")
validation <- validation[cols]
finalPrediction <- predict(model, validation)
finaPrediction

```



#Writing the 20 files out based on the prediction built using the model
```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(finalModel)

```
