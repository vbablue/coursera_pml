<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Practical Machine Learning : Practical machine learning project repository for Coursera">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Practical Machine Learning</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/vbablue/coursera_pml">View on GitHub</a>

          <h1 id="project_title">Practical Machine Learning</h1>
          <h2 id="project_tagline">Practical machine learning project repository for Coursera</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/vbablue/coursera_pml/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/vbablue/coursera_pml/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <p>&lt;!DOCTYPE html&gt;</p>

<p></p>

<p></p>

<p>

</p>

<p></p>



<p>

</p>



code{white-space: pre;}

<p></p>




  pre:not([class]) {
    background-color: white;
  }




<p></p>

<p></p>


.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}


<div>




<div id="machine-learning-model-building">
<h1>
<a id="machine-learning-model-building" class="anchor" href="#machine-learning-model-building" aria-hidden="true"><span class="octicon octicon-link"></span></a>Machine Learning model building</h1>
<div id="load-libraries">
<h3>
<a id="load-libraries" class="anchor" href="#load-libraries" aria-hidden="true"><span class="octicon octicon-link"></span></a>Load libraries</h3>
<p>Load all the libraries that are needed. Caret is the package that we will be interfacing with. parallel package is needed for parallel processing as the model takes some time to run.</p>
<pre><code>suppressPackageStartupMessages(library(caret))</code></pre>
<pre><code>## Warning: package 'caret' was built under R version 3.1.3</code></pre>
<pre><code>suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(parallel))
suppressPackageStartupMessages(library(doParallel))</code></pre>
<pre><code>## Warning: package 'doParallel' was built under R version 3.1.3</code></pre>
</div>

<div id="reading-the-training-data-and-feature-engineering-engineering.">
<h3>
<a id="reading-the-training-data-and-feature-engineering" class="anchor" href="#reading-the-training-data-and-feature-engineering" aria-hidden="true"><span class="octicon octicon-link"></span></a>Reading the training data and feature engineering.</h3>
<p>Read the training data and ignore the NA’s and #DIV/0!. These are clearly visible during the data exploration of the training dataset. First column is having id’s and will have no impact on the model and can be ignored. All the timestamp columns can be ignored as well as they seem to have no impact.</p>
<pre><code>df &lt;- read.csv("pml-training.csv", na.strings=c("NA", "#DIV/0!", ""))
df &lt;- df[,colSums(is.na(df)) == 0]
df &lt;- df[,-1]
df &lt;- select(df, -(raw_timestamp_part_1:cvtd_timestamp))
cols &lt;- colnames(df)</code></pre>
</div>

<p></p>
</div>

<div id="creating-partitions-for-testing-and-training">
<h1>
<a id="creating-partitions-for-testing-and-training" class="anchor" href="#creating-partitions-for-testing-and-training" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating partitions for testing and training</h1>
<p>Create two partitions of the dataset, 60% will be going to training the model and 40% will be going to the testing of the model. The final model is then used to predict the final values.</p>
<pre><code>inTrain &lt;- createDataPartition(y=df$classe,p=0.60, list=FALSE)
training &lt;- df[inTrain,]
testing &lt;- df[-inTrain,]</code></pre>
</div>

<div id="train-the-model-with-random-forests">
<h1>
<a id="train-the-model-with-random-forests" class="anchor" href="#train-the-model-with-random-forests" aria-hidden="true"><span class="octicon octicon-link"></span></a>Train the model with Random forests</h1>
<p>Of the many algorithms avaialble, random forests seems to be the most accurate with good scalibility. The method is used with Cross Validation (part of the caret interface). Also the number of cores are detected to parallellize the process to the number of available cores.</p>
<pre><code>registerDoParallel(clust &lt;- makeCluster(detectCores()))
model &lt;- train(training$classe ~ ., data=training, method="rf",trControl=trainControl(method = "cv", number = 10))</code></pre>
<pre><code>## Loading required package: randomForest
## randomForest 4.6-10
## Type rfNews() to see new features/changes/bug fixes.
## 
## Attaching package: 'randomForest'
## 
## The following object is masked from 'package:dplyr':
## 
##     combine</code></pre>
<pre><code>stopCluster(clust)</code></pre>
<div id="explore-the-results">
<h3>
<a id="explore-the-results" class="anchor" href="#explore-the-results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Explore the results</h3>
<p>Explore the results that the model has given out.</p>
<pre><code>model$results</code></pre>
<pre><code>##   mtry  Accuracy     Kappa  AccuracySD     KappaSD
## 1    2 0.9931218 0.9912991 0.002313010 0.002926221
## 2   30 0.9956695 0.9945221 0.001935976 0.002449618
## 3   59 0.9902347 0.9876474 0.003376556 0.004271980</code></pre>
<pre><code>model$bestTune</code></pre>
<pre><code>##   mtry
## 2   30</code></pre>
<pre><code>model$finalModel</code></pre>
<pre><code>## 
## Call:
##  randomForest(x = x, y = y, mtry = param$mtry) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 30
## 
##         OOB estimate of  error rate: 0.38%
## Confusion matrix:
##      A    B    C    D    E  class.error
## A 3347    0    0    0    1 0.0002986858
## B   10 2265    3    1    0 0.0061430452
## C    0   10 2043    1    0 0.0053554041
## D    0    0    9 1920    1 0.0051813472
## E    0    1    0    8 2156 0.0041570439</code></pre>
</div>

<div id="confusion-matrix-and-out-of-sample-error">
<h3>
<a id="confusion-matrix-and-out-of-sample-error" class="anchor" href="#confusion-matrix-and-out-of-sample-error" aria-hidden="true"><span class="octicon octicon-link"></span></a>Confusion Matrix and Out of Sample Error</h3>
<p>Run a cross validation with the confusion matrix to see accuracy details.</p>
<pre><code>cm &lt;- confusionMatrix(predict(model, newdata=testing), testing$classe)</code></pre>
<p>Take a look at the sensitivity and specificity and other statistics. The accuracy of the model is pretty high and this seems to be a good model.</p>
<pre><code>cm</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 2232    6    0    0    0
##          B    0 1512   11    0    2
##          C    0    0 1357    6    0
##          D    0    0    0 1279    1
##          E    0    0    0    1 1439
## 
## Overall Statistics
##                                          
##                Accuracy : 0.9966         
##                  95% CI : (0.995, 0.9977)
##     No Information Rate : 0.2845         
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16      
##                                          
##                   Kappa : 0.9956         
##  Mcnemar's Test P-Value : NA             
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            1.0000   0.9960   0.9920   0.9946   0.9979
## Specificity            0.9989   0.9979   0.9991   0.9998   0.9998
## Pos Pred Value         0.9973   0.9915   0.9956   0.9992   0.9993
## Neg Pred Value         1.0000   0.9991   0.9983   0.9989   0.9995
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2845   0.1927   0.1730   0.1630   0.1834
## Detection Prevalence   0.2852   0.1944   0.1737   0.1631   0.1835
## Balanced Accuracy      0.9995   0.9970   0.9955   0.9972   0.9989</code></pre>
<pre><code>plot(varImp(model))</code></pre>
<p><img title alt width="672"></p>
</div>

<div id="predict-and-explore-test-dataset">
<h3>
<a id="predict-and-explore-test-dataset" class="anchor" href="#predict-and-explore-test-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Predict and explore (Test dataset)</h3>
<p>Test the newly built model on the testing dataset. Explore the data a little to see the side-by-side comparison of the actual value an dthe predicted value.</p>
<pre><code>prediction &lt;- predict(model, testing) 
new_testing &lt;- cbind(testing,prediction)
#select(new_testing, user_name, classe, prediction)
table(prediction,testing$classe)</code></pre>
<pre><code>##           
## prediction    A    B    C    D    E
##          A 2232    6    0    0    0
##          B    0 1512   11    0    2
##          C    0    0 1357    6    0
##          D    0    0    0 1279    1
##          E    0    0    0    1 1439</code></pre>
</div>

<div id="final-prediction">
<h3>
<a id="final-prediction" class="anchor" href="#final-prediction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Final Prediction</h3>
<p>Reading the validation set or the Final submission set. Read only the columns that were used in predicting the model. Finally, apply the model and look at the predictions. These predictions are correct predictions for all the 20 samples given in the validation set.</p>
<pre><code>validation &lt;- read.csv("pml-testing.csv")
validation &lt;- validation[cols[1:55]]
finalPrediction &lt;- predict(model, validation)
finalPrediction</code></pre>
<pre><code>##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E</code></pre>
</div>

<div id="writing-the-20-files-out-based-on-the-prediction-built-using-the-model">
<h3>
<a id="writing-the-20-files-out-based-on-the-prediction-built-using-the-model" class="anchor" href="#writing-the-20-files-out-based-on-the-prediction-built-using-the-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Writing the 20 files out based on the prediction built using the model</h3>
<p>Boilerplate code to generate the 20 files with 20 prediction for the final project submission.</p>
<pre><code>pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(finalPrediction)</code></pre>
</div>

<p></p>
</div>

<p></p>
</div>







<p>
</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Practical Machine Learning maintained by <a href="https://github.com/vbablue">vbablue</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
